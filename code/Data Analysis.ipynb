{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is used to parse the given data and give a first analysis of the code (Word frequencies, Vocabulary, Lengths of messages, Output analysis...)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sklearn as sk\n",
    "import re\n",
    "import string\n",
    "# We will firstly get the train data \n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "samples_nb = train['toxic'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0005300084f90edc</td>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00054a5e18b50dd4</td>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0006f16e4e9f292e</td>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00070ef96486d6f9</td>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00078f8ce7eb276d</td>\n",
       "      <td>\"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000897889268bc93</td>\n",
       "      <td>REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0009801bd85e5806</td>\n",
       "      <td>The Mitsurugi point made no sense - why not ar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0009eaea3325de8c</td>\n",
       "      <td>Don't mean to bother you \\n\\nI see that you're...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "0   0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1   000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2   000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3   0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4   0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "5   00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...   \n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "7   00031b1e95af7921  Your vandalism to the Matt Shirvington article...   \n",
       "8   00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...   \n",
       "9   00040093b2687caa  alignment on this subject and which are contra...   \n",
       "10  0005300084f90edc  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...   \n",
       "11  00054a5e18b50dd4  bbq \\n\\nbe a man and lets discuss it-maybe ove...   \n",
       "12  0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
       "13  0006f16e4e9f292e  Before you start throwing accusations and warn...   \n",
       "14  00070ef96486d6f9  Oh, and the girl above started her arguments w...   \n",
       "15  00078f8ce7eb276d  \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...   \n",
       "16  0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...   \n",
       "17  000897889268bc93   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski   \n",
       "18  0009801bd85e5806  The Mitsurugi point made no sense - why not ar...   \n",
       "19  0009eaea3325de8c  Don't mean to bother you \\n\\nI see that you're...   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0       0             0        0       0       0              0  \n",
       "1       0             0        0       0       0              0  \n",
       "2       0             0        0       0       0              0  \n",
       "3       0             0        0       0       0              0  \n",
       "4       0             0        0       0       0              0  \n",
       "5       0             0        0       0       0              0  \n",
       "6       1             1        1       0       1              0  \n",
       "7       0             0        0       0       0              0  \n",
       "8       0             0        0       0       0              0  \n",
       "9       0             0        0       0       0              0  \n",
       "10      0             0        0       0       0              0  \n",
       "11      0             0        0       0       0              0  \n",
       "12      1             0        0       0       0              0  \n",
       "13      0             0        0       0       0              0  \n",
       "14      0             0        0       0       0              0  \n",
       "15      0             0        0       0       0              0  \n",
       "16      1             0        0       0       0              0  \n",
       "17      0             0        0       0       0              0  \n",
       "18      0             0        0       0       0              0  \n",
       "19      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have a first look on a few examples\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have a first look on a few examples\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  0000997932d777bf      0             0        0       0       0   \n",
       "1  000103f0d9cfb60f      0             0        0       0       0   \n",
       "2  000113f07ec002fd      0             0        0       0       0   \n",
       "3  0001b41b1c6bb37e      0             0        0       0       0   \n",
       "4  0001d958c54c6e35      0             0        0       0       0   \n",
       "5  00025465d4725e87      0             0        0       0       0   \n",
       "6  0002bcb3da6cb337      1             1        1       0       1   \n",
       "7  00031b1e95af7921      0             0        0       0       0   \n",
       "8  00037261f536c51d      0             0        0       0       0   \n",
       "9  00040093b2687caa      0             0        0       0       0   \n",
       "\n",
       "   identity_hate  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "5              0  \n",
       "6              0  \n",
       "7              0  \n",
       "8              0  \n",
       "9              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we store for later use the output\n",
    "rating_columns = ['id','toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "output = train[rating_columns]\n",
    "output.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...\n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...\n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...\n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We store the inputs\n",
    "inputs = train[['id','comment_text']]\n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how the outputs are distributed\n",
    "output.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 9.5 % of the given comments are toxic, 5% are obscene or/and insults, \n",
    "around 1% are either severe_toxic or identity_hate, and 0.3% are threats (from the mean column).\n",
    "So quite few data are actually categorised.\n",
    "We will be looking at a few samples in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 7 columns):\n",
      "id               159571 non-null object\n",
      "toxic            159571 non-null int64\n",
      "severe_toxic     159571 non-null int64\n",
      "obscene          159571 non-null int64\n",
      "threat           159571 non-null int64\n",
      "insult           159571 non-null int64\n",
      "identity_hate    159571 non-null int64\n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 8.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#Check that we don't have holes in the datas\n",
    "output.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all the data is non-null so we don't have to worry about filling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "\n",
      " Socialistm? \n",
      "\n",
      "There are two important features of Smith's concept of the \"\"invisible hand\"\". First, Smith was not advocating a social policy (that people should act in their own self interest), but rather was describing an observed economic reality (that people do act in their own interest). Second, Smith was not claiming that all self-interest has beneficial effects on the community. He did not argue that self-interest is always good; he merely argued against the view that self-interest is necessarily bad. It is worth noting that, upon his death, Smith left much of his personal wealth to charity.\n",
      "\n",
      "Good!  Let's all make sure we put forth the idea that Adam Smith was a socialist.  That's the wikipedia way!\"\n",
      "-----\n",
      "You are gay or antisemmitian? \n",
      "\n",
      "Archangel WHite Tiger\n",
      "\n",
      "Meow! Greetingshhh!\n",
      "\n",
      "Uh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\n",
      "\n",
      "1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\n",
      "\n",
      "2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\n",
      "\n",
      "3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\n",
      "\n",
      "Beware of the Dark Side!\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"You are gay or antisemmitian? \\n\\nArchangel WHite Tiger\\n\\nMeow! Greetingshhh!\\n\\nUh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\\n\\n1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\\n\\n2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\\n\\n3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\\n\\nBeware of the Dark Side!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Non-Toxic comment\n",
    "print(inputs.loc[150,'comment_text'])\n",
    "print(\"-----\")\n",
    "#Toxic comment\n",
    "print(inputs.loc[42,'comment_text'])\n",
    "print(\"-----\")\n",
    "inputs.loc[42,'comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have some cleaning to do before being able to efficiently use words features/embeddings\n",
    "Some characters such as \"...\" \"!\" \"?\" could give us hints about intensity level in the message so i intend to use them\n",
    "However we will be removing jumps as /n.\n",
    "A first clue here might be the insults. Those ones should be easy to detect thanks to a vocabulary or an embedding. We can already imagine that we could have a toxicity rating per word which should help us to give a good general categorization. UpperCase and punctuation can also be features for our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before any feature extraction we are going to do some cleaning while keeping some usable features\n",
    "\n",
    "# Counting chars\n",
    "inputs['nb_char'] = inputs['comment_text'].map(lambda x:len(x))\n",
    "\n",
    "# nb of words\n",
    "inputs['nb_word'] = inputs['comment_text'].map(lambda x:len(re.findall(r'\\w+', x)))\n",
    "\n",
    "# Counting % of UpperCase\n",
    "inputs['per_upper_case'] = inputs['comment_text'].map(lambda x:sum(1 for c in x if c.isupper())/len(x))\n",
    "\n",
    "# Counting punctuations such as . ! ; , ? ) or (\n",
    "inputs['dot'] = inputs['comment_text'].map(lambda x:x.count('.')/len(x))\n",
    "inputs['exclamation'] = inputs['comment_text'].map(lambda x:x.count('!')/len(x))\n",
    "inputs['semi-colon'] = inputs['comment_text'].map(lambda x:x.count(';')/len(x))\n",
    "inputs['comma'] = inputs['comment_text'].map(lambda x:x.count(',')/len(x))\n",
    "inputs['question'] = inputs['comment_text'].map(lambda x:x.count('?')/len(x))\n",
    "inputs['double_dot'] = inputs['comment_text'].map(lambda x:x.count(':')/len(x))\n",
    "inputs['parenthesis'] = inputs['comment_text'].map(lambda x:(x.count(')')+x.count('('))/len(x))\n",
    "inputs['hooks'] = inputs['comment_text'].map(lambda x:(x.count(']')+x.count('['))/len(x))\n",
    "\n",
    "extra_features_list=['nb_char','nb_word','dot','exclamation','semi-colon','comma','question','double_dot','parenthesis','hooks']\n",
    "# Cleaning special characters, lowering cases, punctuation and stopwords are dealt with sklearn\n",
    "# We are left with some lemmatization to deal with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_char</th>\n",
       "      <th>nb_word</th>\n",
       "      <th>per_upper_case</th>\n",
       "      <th>dot</th>\n",
       "      <th>exclamation</th>\n",
       "      <th>semi-colon</th>\n",
       "      <th>comma</th>\n",
       "      <th>question</th>\n",
       "      <th>double_dot</th>\n",
       "      <th>parenthesis</th>\n",
       "      <th>hooks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15294.000000</td>\n",
       "      <td>15294.000000</td>\n",
       "      <td>15294.000000</td>\n",
       "      <td>15294.000000</td>\n",
       "      <td>15294.000000</td>\n",
       "      <td>15294.000000</td>\n",
       "      <td>15294.000000</td>\n",
       "      <td>15294.000000</td>\n",
       "      <td>15294.000000</td>\n",
       "      <td>15294.000000</td>\n",
       "      <td>15294.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>295.246044</td>\n",
       "      <td>53.306133</td>\n",
       "      <td>0.114575</td>\n",
       "      <td>0.016111</td>\n",
       "      <td>0.009258</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.006225</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.001212</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>617.379025</td>\n",
       "      <td>110.144107</td>\n",
       "      <td>0.211694</td>\n",
       "      <td>0.022851</td>\n",
       "      <td>0.040792</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.009069</td>\n",
       "      <td>0.011741</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>0.002803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.019376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.011070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>271.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.069964</td>\n",
       "      <td>0.021071</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>1403.000000</td>\n",
       "      <td>0.998189</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.994366</td>\n",
       "      <td>0.102362</td>\n",
       "      <td>0.142576</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.202247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nb_char       nb_word  per_upper_case           dot   exclamation  \\\n",
       "count  15294.000000  15294.000000    15294.000000  15294.000000  15294.000000   \n",
       "mean     295.246044     53.306133        0.114575      0.016111      0.009258   \n",
       "std      617.379025    110.144107        0.211694      0.022851      0.040792   \n",
       "min        8.000000      2.000000        0.000000      0.000000      0.000000   \n",
       "25%       59.000000     11.000000        0.019376      0.000000      0.000000   \n",
       "50%      123.000000     23.000000        0.035088      0.011070      0.000000   \n",
       "75%      271.000000     50.000000        0.069964      0.021071      0.002021   \n",
       "max     5000.000000   1403.000000        0.998189      0.590909      0.994366   \n",
       "\n",
       "         semi-colon         comma      question    double_dot   parenthesis  \\\n",
       "count  15294.000000  15294.000000  15294.000000  15294.000000  15294.000000   \n",
       "mean       0.000139      0.006225      0.002908      0.000727      0.001212   \n",
       "std        0.001617      0.009069      0.011741      0.003662      0.005535   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.010097      0.000000      0.000000      0.000000   \n",
       "max        0.102362      0.142576      0.556818      0.100000      0.162162   \n",
       "\n",
       "              hooks  \n",
       "count  15294.000000  \n",
       "mean       0.000158  \n",
       "std        0.002803  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        0.202247  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.loc[train['toxic']==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_char</th>\n",
       "      <th>nb_word</th>\n",
       "      <th>per_upper_case</th>\n",
       "      <th>dot</th>\n",
       "      <th>exclamation</th>\n",
       "      <th>semi-colon</th>\n",
       "      <th>comma</th>\n",
       "      <th>question</th>\n",
       "      <th>double_dot</th>\n",
       "      <th>parenthesis</th>\n",
       "      <th>hooks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>144277.000000</td>\n",
       "      <td>144277.000000</td>\n",
       "      <td>144277.000000</td>\n",
       "      <td>144277.000000</td>\n",
       "      <td>144277.000000</td>\n",
       "      <td>144277.000000</td>\n",
       "      <td>144277.000000</td>\n",
       "      <td>144277.000000</td>\n",
       "      <td>144277.000000</td>\n",
       "      <td>144277.000000</td>\n",
       "      <td>144277.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>404.549339</td>\n",
       "      <td>70.859174</td>\n",
       "      <td>0.044949</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>0.000414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>586.850889</td>\n",
       "      <td>101.175399</td>\n",
       "      <td>0.065708</td>\n",
       "      <td>0.015078</td>\n",
       "      <td>0.012004</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>0.005939</td>\n",
       "      <td>0.009557</td>\n",
       "      <td>0.004370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>216.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.031549</td>\n",
       "      <td>0.010471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>453.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.016333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.917197</td>\n",
       "      <td>0.129353</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.318777</td>\n",
       "      <td>0.194444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             nb_char        nb_word  per_upper_case            dot  \\\n",
       "count  144277.000000  144277.000000   144277.000000  144277.000000   \n",
       "mean      404.549339      70.859174        0.044949       0.013565   \n",
       "std       586.850889     101.175399        0.065708       0.015078   \n",
       "min         6.000000       1.000000        0.000000       0.000000   \n",
       "25%       102.000000      18.000000        0.020833       0.006494   \n",
       "50%       216.000000      39.000000        0.031549       0.010471   \n",
       "75%       453.000000      80.000000        0.047619       0.016333   \n",
       "max      5000.000000    1250.000000        0.962963       0.873874   \n",
       "\n",
       "         exclamation     semi-colon          comma       question  \\\n",
       "count  144277.000000  144277.000000  144277.000000  144277.000000   \n",
       "mean        0.001553       0.000290       0.007211       0.002047   \n",
       "std         0.012004       0.001769       0.007863       0.007693   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.006173       0.000000   \n",
       "75%         0.000000       0.000000       0.010638       0.000459   \n",
       "max         0.917197       0.129353       0.268657       0.598131   \n",
       "\n",
       "          double_dot    parenthesis          hooks  \n",
       "count  144277.000000  144277.000000  144277.000000  \n",
       "mean        0.002070       0.003631       0.000414  \n",
       "std         0.005939       0.009557       0.004370  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000  \n",
       "75%         0.001359       0.003526       0.000000  \n",
       "max         0.394737       0.318777       0.194444  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.loc[train['toxic']==0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at the boxplot representation with the simples features we gathered for the toxic category comparison\n",
    "dfBPl = pd.concat([inputs,train[rating_columns[0]]],axis=1)\n",
    "dfBPl.boxplot(showfliers=False,by='toxic',column=['per_upper_case','dot','hooks','double_dot','exclamation','semi-colon','comma','question','parenthesis'],figsize=[16,16])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a first look it seems that some of our features might be usable even if not strongly separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to create the features from the comments\n",
    "\n",
    "# Bags of words/ Occurences (mono and bi-grams)\n",
    "from sklearn.feature_extraction.text import *\n",
    "count_vect = CountVectorizer(ngram_range=(1, 2))\n",
    "count_train = count_vect.fit_transform(inputs['comment_text'])\n",
    "\n",
    "# tf-idf\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_train = tfidf_transformer.fit_transform(count_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to do the same from the chars\n",
    "\n",
    "# Bags of words\n",
    "count_char_vect = CountVectorizer(analyzer='char',ngram_range=(1, 3))\n",
    "count_char_train = count_char_vect.fit_transform(inputs['comment_text'])\n",
    "\n",
    "#tf-idf\n",
    "tfidf_char_transformer = TfidfTransformer()\n",
    "tfidf_char_train = tfidf_transformer.fit_transform(count_char_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use SVD (/LSA) to visualize if the toxicity is well separated with tfidf for words or chars\n",
    "from sklearn import decomposition\n",
    "from sklearn.pipeline import make_pipeline\n",
    "SVD = decomposition.TruncatedSVD(n_components=3)\n",
    "normalizer = sk.preprocessing.Normalizer(copy=False)\n",
    "lsa = make_pipeline(SVD, normalizer)\n",
    "result = lsa.fit_transform(tfidf_train)\n",
    "result_char = lsa.fit_transform(tfidf_char_train)\n",
    "\n",
    "#We will use PCA for our features \n",
    "PCA = decomposition.PCA(n_components=3)\n",
    "normalizer = sk.preprocessing.Normalizer(copy=False)\n",
    "pcaPipe = make_pipeline(PCA, normalizer)\n",
    "resultFeatures = pcaPipe.fit_transform(inputs[extra_features_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0657823  0.01355035 0.0094751 ]\n"
     ]
    }
   ],
   "source": [
    "# Visualisation of LSA for words\n",
    "print(SVD.explained_variance_ratio_)\n",
    "fig = plt.figure(figsize=[16,8])\n",
    "ax = fig.add_subplot(111)\n",
    "colors = ['blue','red']\n",
    "for i in range(1,samples_nb):\n",
    "    ax.scatter(result[i,0],result[i,1], color= colors[int(train['toxic'][i])],marker=0)\n",
    "plt.xlabel('LSA1')\n",
    "plt.ylabel('LSA2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of LSA for chars\n",
    "print(SVD.explained_variance_ratio_)\n",
    "fig = plt.figure(figsize=[16,8])\n",
    "ax = fig.add_subplot(111,projection='3d')\n",
    "colors = ['blue','red']\n",
    "for i in range(5000,10000):\n",
    "    ax.scatter(result_char[i,0],result_char[i,1],result_char[i,2], color= colors[int(train['toxic'][i])],marker=0)\n",
    "plt.xlabel('LSA1')\n",
    "plt.ylabel('LSA2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA for our features\n",
    "print(PCA.explained_variance_ratio_)\n",
    "fig = plt.figure(figsize=[16,8])\n",
    "ax = fig.add_subplot(111,projection='3d')\n",
    "colors = ['blue','red']\n",
    "for i in range(5000,10000):\n",
    "    ax.scatter(resultFeatures[i,0],resultFeatures[i,1],resultFeatures[i,2], color= colors[int(train['toxic'][i])],marker=3)\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to use our features to try some classifications methods to predict score upon our features\n",
    "\n",
    "# We will be first using LogisticRegression as we are here trying to predict classes, sklearn implementation will be used\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "xTrain = hstack([tfidf_train,tfidf_char_train])\n",
    "xTrain = hstack([xTrain,inputs[extra_features_list]])\n",
    "\n",
    "logreg = LogisticRegression(C=1e5,solver='saga')\n",
    "#Naive bayesian estimation\n",
    "def pr(y_i, y):\n",
    "    p = xTrain[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)\n",
    "\n",
    "# Logistic Regression\n",
    "def get_mdl(y):\n",
    "    y = y.values\n",
    "    r = np.log(pr(1,y) / pr(0,y))\n",
    "    m = LogisticRegression(C=4, dual=True)\n",
    "    xTrain_nb = xTrain.multiply(r)\n",
    "    return m.fit(xTrain_nb, y), r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-223-425db9db1fc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#preds[:,1] = m.predict_proba(xTrain.multiply(r))[:,1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mestimations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxTrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'toxic'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mestimations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "logreg.fit(xTrain,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0001511634006545636"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionTrain = logreg.predict_proba(xTrain)\n",
    "np.mean(predictionTrain[:,1]-train['toxic'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
