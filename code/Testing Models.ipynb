{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain data\n",
    "train_input, train_output, test_input, all_input = data.getDataFrom('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 25011)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features extraction from the text\n",
    "# Set pipelines for word and char feature extraction\n",
    "count_char_vect = CountVectorizer(analyzer='char',ngram_range=(3, 6), max_features=15000)\n",
    "tfidf_char_transformer = TfidfTransformer(sublinear_tf=True)\n",
    "charPipe = make_pipeline(count_char_vect,tfidf_char_transformer)\n",
    "\n",
    "count_word_vect = CountVectorizer(ngram_range=(1, 2), max_features = 10000)\n",
    "tfidf_word_transformer = TfidfTransformer(sublinear_tf=True)\n",
    "wordPipe = make_pipeline(count_word_vect,tfidf_word_transformer)\n",
    "\n",
    "charPipe.fit(train_input['comment_text'])\n",
    "wordPipe.fit(train_input['comment_text'])\n",
    "# apply extraction\n",
    "extra, word, char = data.getFeatures(train_input, wordPipe, charPipe)\n",
    "features_train = hstack([extra,word,char])\n",
    "\n",
    "# And for test data\n",
    "extra_test, word_test, char_test = data.getFeatures(test_input, wordPipe, charPipe)\n",
    "features_test = hstack([extra_test,word_test,char_test])\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the model (from cell)\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSA + Logistic Regression\n",
    "SVD = decomposition.TruncatedSVD(n_components=50)\n",
    "normalizer = Normalizer(copy=False)\n",
    "logreg = LogisticRegression(C=5)\n",
    "model = make_pipeline(SVD, normalizer,logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSA + SVM\n",
    "SVD = decomposition.TruncatedSVD(n_components=50)\n",
    "normalizer = Normalizer(copy=False)\n",
    "svc = SVC(C=1.0, kernel=\"rbf\", probability=True)\n",
    "model = make_pipeline(SVD, normalizer,svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Apply the model with a crossval\n",
    "prediction={'id':test_input['id']}\n",
    "for output_name in train_output.columns:\n",
    "    cv_loss = cross_val_score(model,features_train,train_output[output_name],cv = 5)\n",
    "    print('CV score for column {} is {}'.format(output_name, cv_loss))\n",
    "    model.fit(features_train,train_output[output_name])\n",
    "    prediction[output_name] = model.predict_proba(features_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format submission\n",
    "submission = pd.DataFrame.from_dict(prediction)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x22 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debug Cell(s)\n",
    "features_train.shape\n",
    "char.shape\n",
    "analyze = count_char_vect.build_analyzer()\n",
    "res = charPipe.transform([\"Hey ! Sasfuhfhfqz65sd65fds6dsffsd5lutfdgsdggsd\"])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction['train'] = model.predict_proba(features_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07269556065122973"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction['train'][159557]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
